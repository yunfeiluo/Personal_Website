{"0": {"obj": {"docs": [{"docs": [], "path": "articles/documentations/personal_website/Requirements.pdf", "text": "Personal Website, Requirements\nAuthor: Yunfei Luo\n1. Functionalities.\n1.1. Welcome page\nWhen user navigate to the website, there is a clean-style page, with brief introduction, links to the documents, and nice pictures. There is also a footer at the bottom of the webpage, containing the linkedin, github, and my contact information. This footer will be shown in all the webpages on the website. \n\n1.2. Navigation to documents\nUser click on the link with either: \ni) navigate to software engineering documentations\nii) navigate to reports of open source projects\niii) navigate to blogs\niv) navigate to search area! :)\nFor the first three cases, the list of corresponding documents will be shown with a clean style. When user click on the title, the documents need to be shown explicitly. AND, there need to be a back button to let the user navigate back to the list page. \n\n1.3. Search for relevant document(s)\nUser click into the search area. They will search with key words: blogs, reports, image process, language model, what is search engine, what is this, to be or not to be, hey what's up! ...\n\nThe retrieved list will be shown in the same form mentioned in 1.2. The search bar will keep at the top of the webpage. The user could either click the document for reading (also same scenario in 1.2.), or try another query, or close the browser. \n\n2. Non-Functionalities.\n2.1. Development Schema: Waterfall, CI/CD\nSince this is a personal project, waterfall pattern is a proper way to keep the progress going forward stably and correctly. Continuous Integration enable the consistency of codes among local development branch and the remote master branch. \n\n2.2. Front-end Tool(s): React\nThe render functionality of React enables the concise response the quick and temporary click actions. The JSX syntax enables the effective development, and makes the code more readable. \n\n2.3. Back-end Tool(s): Flask, AWS\nFlask is used for local testing, i.e. setup a local server, and test the interactions between front-end and back-end. \n\nAWS provide cloud services that enables the quick deployment. The services that will be used include: S3 bucket for server, Lambda functions for handling events, API Gateway for the communication between front-end and back-end, and Relational Database Service for indexing the articles. \n\n2.4. Version Control: Github\nA widely recognized tool for version control. Github offer clean interface to trace the issues, and push/pull requests. ", "id": 2, "summery": "The functionalities and the non-functionalities of the personal website project; stating the reasons for the chosen tools and patterns.", "tags": ["Software Engineering", "Full Stack"], "type": "documentation", "title": "Requirements Analysis, Personal Website"}, {"docs": [], "path": "articles/documentations/personal_website/high_level_design.pdf", "text": "1. Overview.\nFigure 1. Entire Architecture\n \n2. Front-end Schema.\nFigure 2. Frontend Architecture\n \nHomepage is the node connecting the website to with users. Search page is the node connecting the frontend to the backend. Both Homepage and Search page navigate to the article pages.\n \nEvery pages return to the homepage. \n \nEvery pages contain Contact info in the footer. \n \n3. Back-end Scheme.\nFigure 3. Backtend Architecture.\n \nEvent Handler is the node receiving requests from the frontend. It will run the micro search engine, and return the result back to the frontend. \n \nWithin the micro search engine, the Store Documents and Index contains the data needed for retrieving the documents. The retrieval model rank the documents based on the stored data, and return the result back to the Event handler node. \n \n4. Database Schema.\nincludegraphics[scale=0.21]{article_stored.jpg}\nFigure 4. table for storing Article object\n \nEach article has a unique id. Type attribute could be ${$blogs, reports, documentations$}$. Path attribute specifies where the document stored. Docs attribute points to other documents that is within the scope of project of the Article object. ", "id": 3, "summery": "Displaying the Entire Architecture of the personal website project; Schemas for Front-end, Back-end, and Database.", "tags": ["Software Engineering", "Full Stack"], "title": "High Level Design, Personal Website", "type": "documentation"}, {"docs": [], "path": "articles/documentations/personal_website/low_level_design_search_engine.pdf", "text": "\title{Personal Website, Low Level Design, Search Engine}\n\\author{Author: Yunfei Luo}\n\\maketitle\n\n------------------------------------------------------------------------------------------------------------------------\n\\ \\\n\textbf{1. Overview.}\n\\ \\\n\\includegraphics[scale=0.28]{back_end_overview.jpg}\\\n\\centerline{\textbf{Figure 1. }Micro Search Engine Architecture}\n\\ \\\n\textbf{2. Pre-processing.}\\\n\textbf{2.1. Processing Documents.}\\\nThis is independent with the interaction between frontend and backend. This process need to be done periodically, or whenever there are new articles added to the database. \n\\ \\\nThe process follows steps:\\\ni) tokenize, all letter to lower case, and remove dot between abbreviation words. \\\nii) stemming, use Snowball stemmer, also called Porter 2. \\\niii) stopword removal, remove non-significant words, use the concise list from python package: nltk.  \\\n\\ \\\n\\ \\\n\textbf{2.2. Processing Queries.}\\\nWhen ever there is a query request coming from frontend, the query terms will first be pre-processed, then the querying functions will be executed. The processing steps are the same as steps for processing documents, see 2.1.\n\\ \\\n\textbf{3. Indexing (Inverted Index).}\\\nIndexing will be mainly used by the retrieval model to rank the documents given the query terms. Inverted Index is a inverted list, that contains the necessary information for each stored terms. More specifically, the inverted index is defined as:\\\n$$map: term \\mapsto (map: document\\_id \\mapsto list(positions))$$\nFor example, term $learning$ occur in document 1 and 3. It is the first and fifth word of document 1, and second and forth word of document 2, then the index for this term would looks like:\n$$learning \\mapsto \\{document_1 \\mapsto [1, 5], document_3 \\mapsto [2, 4] \\}$$\nThen the term frequency in a document is $length(term.doc\\_id)$, i.e. the total length of the list of positions in document with specified id. The collection frequency is the length of the list for a term. \n\\ \\\n\textbf{4. Retrieval Models.}\\\nThe key element for ranking the documents given the query terms. The following are the options of algorithms. \n\\ \\\n\textbf{4.1. BM25. (formula information reference from: Search Engines,\nInformation Retrieval in Practice, by W.B. Croft, D. Metzler, T. Strohman, 2015)}\\\nBM25 (BM stands for Best Match) is a well-known probabilistic retrieval model that not only take the document term frequency into account, but also consider the query term frequency. In the micro search engine, we will use the most common form of BM25, with no reference information. More specifically, the score for a document given the query terms is calculated by:\n$$\\sum_{i \\in Q} \\log(\frac{N-n_i+0.5}{n_i+0.5}) \\cdot \frac{(k_1+1)f_i}{K + f_i} \\cdot \frac{(k_2+1)qf_i}{k_2+qf_i}$$\nWhere $Q$ is the set of terms in the query terms, $N$ is the total number of documents we have, $n_i$ is the document frequency, i.e. number of documents that contain term $i$. $f_i$ is the term frequency in the document, and $qf_i$ is the term frequency in the query terms. The weighting parameters $k_1, k_2, K$ are set empirically (by science). $k_1$ and $k_2$ determine the importance of document term frequency and query term frequency respectively. $K$ is a normalized term, determined by:\n$$K = k_1((1-b)+b\\cdot \frac{dl}{avdl})$$\nWhere $b$ is a empirical parameter, $dl$ is the document length, and $avdl$ is the average length of all the documents we have. \n\\ \\\nWe could set the magic parameters to $k_1=1.1, k_2=10, b=0.6$. \n\\ \\\n\textbf{4.2. Query Likelihood. (formula information reference from: Search Engines,\nInformation Retrieval in Practice, by W.B. Croft, D. Metzler, T. Strohman, 2015)}\\\nQuery Likelihood is a well-known probabilistic retrieval model depends on language model. The smoothing techniques we use is Dirichlet smoothing. More specifically, we calculate the score for a document by:\n$$\\alpha_D P(q_i|D) + \\alpha_D P(q_i|C)$$\nwhere $P(q_i|D)$ is the probability of query term $i$ occur in document $D$, and $P(q_i|C)$ is the probability of query term $i$ occur in the entire collection $C$. $\\alpha_D$ is the Dirichlet smoothing coefficient determined by $\\alpha_D = \frac{\\mu}{|D| + \\mu}$, where $\\mu$ is set empirically. The final formula is:\n$$\frac{f_{q_i, D} + \\mu \frac{c_{q_i}}{|C|}}{|D| + \\mu}$$\nwhere $f_{q_i, D}$ is the term frequency in document $D$, and $c_{q_i}$ is the term frequency in entire collection $C$. We could set $\\mu = 1000$. ", "id": 4, "summery": "Details of the micro search engine, including the steps for query processing, indexing techniques, and retrieval models.", "tags": ["Software Engineering", "Full Stack", "Search Engine"], "title": "Low level Design -- Search Engine, Personal Website", "type": "documentation"}], "path": "articles/documentations/personal_website/Introduction.pdf", "text": "Personal Website Introduction\nAuthor: Yunfei Luo\nThis website was mainly designed for representing the Software Engineering and open source projects that I've\ndone or participated in.\n\\ \\\nThere are reports and documentaions of the projects. Moreover, there are blogs, include the reflections and discussions on the papers of the related fields that I've read. The blogs also include some of my learning\nnotes on the significant concepts in the engineering (application) field. \n\\ \\\nThere is a micro-search-engine implemented in the backend to enable the search functionalities. Since the articles are stored structured in a retrospective way, they are easy to be retrieved and be able to concisely displayed to the readers.\n\\ \\\nThe website well-come all readers who are interested in the topics of these articles. Enjoy the reading! ", "id": 1, "summery": "This website was mainly designed for representing the Software Engineering and open source projects that I've done or participated in.", "tags": ["Software Engineering", "Full Stack"], "type": "documentation", "title": "Personal Website, Software Engineering Project"}, "text": ["personal", "website", "introduction", "author", "yunfei", "luo", "website", "mainly", "designed", "representing", "software", "engineering", "open", "source", "projects", "ve", "done", "participated", "reports", "documentaions", "projects", "blogs", "reflections", "discussions", "papers", "related", "fields", "ve", "read", "blogs", "learning", "notes", "significant", "concepts", "engineering", "application", "field", "micro", "search", "engine", "implemented", "backend", "enable", "search", "functionalities", "articles", "stored", "structured", "retrospective", "way", "easy", "retrieved", "able", "concisely", "displayed", "readers", "website", "come", "readers", "interested", "topics", "articles", "enjoy", "reading"]}, "1": {"obj": {"docs": [], "path": "articles/documentations/personal_website/Requirements.pdf", "text": "Personal Website, Requirements\nAuthor: Yunfei Luo\n1. Functionalities.\n1.1. Welcome page\nWhen user navigate to the website, there is a clean-style page, with brief introduction, links to the documents, and nice pictures. There is also a footer at the bottom of the webpage, containing the linkedin, github, and my contact information. This footer will be shown in all the webpages on the website. \n\n1.2. Navigation to documents\nUser click on the link with either: \ni) navigate to software engineering documentations\nii) navigate to reports of open source projects\niii) navigate to blogs\niv) navigate to search area! :)\nFor the first three cases, the list of corresponding documents will be shown with a clean style. When user click on the title, the documents need to be shown explicitly. AND, there need to be a back button to let the user navigate back to the list page. \n\n1.3. Search for relevant document(s)\nUser click into the search area. They will search with key words: blogs, reports, image process, language model, what is search engine, what is this, to be or not to be, hey what's up! ...\n\nThe retrieved list will be shown in the same form mentioned in 1.2. The search bar will keep at the top of the webpage. The user could either click the document for reading (also same scenario in 1.2.), or try another query, or close the browser. \n\n2. Non-Functionalities.\n2.1. Development Schema: Waterfall, CI/CD\nSince this is a personal project, waterfall pattern is a proper way to keep the progress going forward stably and correctly. Continuous Integration enable the consistency of codes among local development branch and the remote master branch. \n\n2.2. Front-end Tool(s): React\nThe render functionality of React enables the concise response the quick and temporary click actions. The JSX syntax enables the effective development, and makes the code more readable. \n\n2.3. Back-end Tool(s): Flask, AWS\nFlask is used for local testing, i.e. setup a local server, and test the interactions between front-end and back-end. \n\nAWS provide cloud services that enables the quick deployment. The services that will be used include: S3 bucket for server, Lambda functions for handling events, API Gateway for the communication between front-end and back-end, and Relational Database Service for indexing the articles. \n\n2.4. Version Control: Github\nA widely recognized tool for version control. Github offer clean interface to trace the issues, and push/pull requests. ", "id": 2, "summery": "The functionalities and the non-functionalities of the personal website project; stating the reasons for the chosen tools and patterns.", "tags": ["Software Engineering", "Full Stack"], "type": "documentation", "title": "Requirements Analysis, Personal Website"}, "text": ["personal", "website", "requirements", "author", "yunfei", "luo", "1", "functionalities", "11", "welcome", "page", "user", "navigate", "website", "clean", "style", "page", "brief", "introduction", "links", "documents", "nice", "pictures", "footer", "bottom", "webpage", "containing", "linkedin", "github", "contact", "information", "footer", "webpages", "website", "12", "navigation", "documents", "user", "click", "link", "navigate", "software", "engineering", "documentations", "ii", "navigate", "reports", "open", "source", "projects", "iii", "navigate", "blogs", "iv", "navigate", "search", "area", "three", "cases", "list", "corresponding", "documents", "clean", "style", "user", "click", "title", "documents", "explicitly", "back", "button", "user", "navigate", "back", "list", "page", "13", "search", "relevant", "document", "s", "user", "click", "search", "area", "search", "key", "words", "blogs", "reports", "image", "process", "language", "model", "search", "engine", "hey", "s", "", "", "", "retrieved", "list", "form", "mentioned", "12", "search", "bar", "keep", "top", "webpage", "user", "click", "document", "reading", "scenario", "12", "try", "query", "close", "browser", "2", "non", "functionalities", "21", "development", "schema", "waterfall", "ci", "cd", "personal", "project", "waterfall", "pattern", "proper", "way", "keep", "progress", "going", "stably", "correctly", "continuous", "integration", "enable", "consistency", "codes", "local", "development", "branch", "remote", "master", "branch", "22", "end", "tool", "s", "react", "render", "functionality", "react", "enables", "concise", "response", "quick", "temporary", "click", "actions", "jsx", "syntax", "enables", "effective", "development", "makes", "code", "readable", "23", "back", "end", "tool", "s", "flask", "aws", "flask", "local", "testing", "setup", "local", "server", "test", "interactions", "end", "back", "end", "aws", "cloud", "services", "enables", "quick", "deployment", "services", "s3", "bucket", "server", "lambda", "functions", "handling", "events", "api", "gateway", "communication", "end", "back", "end", "relational", "database", "service", "indexing", "articles", "24", "version", "control", "github", "widely", "recognized", "tool", "version", "control", "github", "offer", "clean", "interface", "trace", "issues", "push", "pull", "requests"]}, "2": {"obj": {"docs": [], "path": "articles/documentations/personal_website/high_level_design.pdf", "text": "1. Overview.\nFigure 1. Entire Architecture\n \n2. Front-end Schema.\nFigure 2. Frontend Architecture\n \nHomepage is the node connecting the website to with users. Search page is the node connecting the frontend to the backend. Both Homepage and Search page navigate to the article pages.\n \nEvery pages return to the homepage. \n \nEvery pages contain Contact info in the footer. \n \n3. Back-end Scheme.\nFigure 3. Backtend Architecture.\n \nEvent Handler is the node receiving requests from the frontend. It will run the micro search engine, and return the result back to the frontend. \n \nWithin the micro search engine, the Store Documents and Index contains the data needed for retrieving the documents. The retrieval model rank the documents based on the stored data, and return the result back to the Event handler node. \n \n4. Database Schema.\nincludegraphics[scale=0.21]{article_stored.jpg}\nFigure 4. table for storing Article object\n \nEach article has a unique id. Type attribute could be ${$blogs, reports, documentations$}$. Path attribute specifies where the document stored. Docs attribute points to other documents that is within the scope of project of the Article object. ", "id": 3, "summery": "Displaying the Entire Architecture of the personal website project; Schemas for Front-end, Back-end, and Database.", "tags": ["Software Engineering", "Full Stack"], "title": "High Level Design, Personal Website", "type": "documentation"}, "text": ["1", "overview", "figure", "1", "entire", "architecture", "2", "end", "schema", "figure", "2", "frontend", "architecture", "homepage", "node", "connecting", "website", "users", "search", "page", "node", "connecting", "frontend", "backend", "homepage", "search", "page", "navigate", "article", "pages", "pages", "return", "homepage", "pages", "contain", "contact", "info", "footer", "3", "back", "end", "scheme", "figure", "3", "backtend", "architecture", "event", "handler", "node", "receiving", "requests", "frontend", "run", "micro", "search", "engine", "return", "result", "back", "frontend", "micro", "search", "engine", "store", "documents", "index", "contains", "data", "needed", "retrieving", "documents", "retrieval", "model", "rank", "documents", "based", "stored", "data", "return", "result", "back", "event", "handler", "node", "4", "database", "schema", "includegraphics", "scale", "0", "21", "article", "stored", "jpg", "figure", "4", "table", "storing", "article", "object", "article", "unique", "id", "type", "attribute", "blogs", "reports", "documentations", "", "path", "attribute", "specifies", "document", "stored", "docs", "attribute", "points", "documents", "scope", "project", "article", "object"]}, "3": {"obj": {"docs": [], "path": "articles/documentations/personal_website/low_level_design_search_engine.pdf", "text": "\title{Personal Website, Low Level Design, Search Engine}\n\\author{Author: Yunfei Luo}\n\\maketitle\n\n------------------------------------------------------------------------------------------------------------------------\n\\ \\\n\textbf{1. Overview.}\n\\ \\\n\\includegraphics[scale=0.28]{back_end_overview.jpg}\\\n\\centerline{\textbf{Figure 1. }Micro Search Engine Architecture}\n\\ \\\n\textbf{2. Pre-processing.}\\\n\textbf{2.1. Processing Documents.}\\\nThis is independent with the interaction between frontend and backend. This process need to be done periodically, or whenever there are new articles added to the database. \n\\ \\\nThe process follows steps:\\\ni) tokenize, all letter to lower case, and remove dot between abbreviation words. \\\nii) stemming, use Snowball stemmer, also called Porter 2. \\\niii) stopword removal, remove non-significant words, use the concise list from python package: nltk.  \\\n\\ \\\n\\ \\\n\textbf{2.2. Processing Queries.}\\\nWhen ever there is a query request coming from frontend, the query terms will first be pre-processed, then the querying functions will be executed. The processing steps are the same as steps for processing documents, see 2.1.\n\\ \\\n\textbf{3. Indexing (Inverted Index).}\\\nIndexing will be mainly used by the retrieval model to rank the documents given the query terms. Inverted Index is a inverted list, that contains the necessary information for each stored terms. More specifically, the inverted index is defined as:\\\n$$map: term \\mapsto (map: document\\_id \\mapsto list(positions))$$\nFor example, term $learning$ occur in document 1 and 3. It is the first and fifth word of document 1, and second and forth word of document 2, then the index for this term would looks like:\n$$learning \\mapsto \\{document_1 \\mapsto [1, 5], document_3 \\mapsto [2, 4] \\}$$\nThen the term frequency in a document is $length(term.doc\\_id)$, i.e. the total length of the list of positions in document with specified id. The collection frequency is the length of the list for a term. \n\\ \\\n\textbf{4. Retrieval Models.}\\\nThe key element for ranking the documents given the query terms. The following are the options of algorithms. \n\\ \\\n\textbf{4.1. BM25. (formula information reference from: Search Engines,\nInformation Retrieval in Practice, by W.B. Croft, D. Metzler, T. Strohman, 2015)}\\\nBM25 (BM stands for Best Match) is a well-known probabilistic retrieval model that not only take the document term frequency into account, but also consider the query term frequency. In the micro search engine, we will use the most common form of BM25, with no reference information. More specifically, the score for a document given the query terms is calculated by:\n$$\\sum_{i \\in Q} \\log(\frac{N-n_i+0.5}{n_i+0.5}) \\cdot \frac{(k_1+1)f_i}{K + f_i} \\cdot \frac{(k_2+1)qf_i}{k_2+qf_i}$$\nWhere $Q$ is the set of terms in the query terms, $N$ is the total number of documents we have, $n_i$ is the document frequency, i.e. number of documents that contain term $i$. $f_i$ is the term frequency in the document, and $qf_i$ is the term frequency in the query terms. The weighting parameters $k_1, k_2, K$ are set empirically (by science). $k_1$ and $k_2$ determine the importance of document term frequency and query term frequency respectively. $K$ is a normalized term, determined by:\n$$K = k_1((1-b)+b\\cdot \frac{dl}{avdl})$$\nWhere $b$ is a empirical parameter, $dl$ is the document length, and $avdl$ is the average length of all the documents we have. \n\\ \\\nWe could set the magic parameters to $k_1=1.1, k_2=10, b=0.6$. \n\\ \\\n\textbf{4.2. Query Likelihood. (formula information reference from: Search Engines,\nInformation Retrieval in Practice, by W.B. Croft, D. Metzler, T. Strohman, 2015)}\\\nQuery Likelihood is a well-known probabilistic retrieval model depends on language model. The smoothing techniques we use is Dirichlet smoothing. More specifically, we calculate the score for a document by:\n$$\\alpha_D P(q_i|D) + \\alpha_D P(q_i|C)$$\nwhere $P(q_i|D)$ is the probability of query term $i$ occur in document $D$, and $P(q_i|C)$ is the probability of query term $i$ occur in the entire collection $C$. $\\alpha_D$ is the Dirichlet smoothing coefficient determined by $\\alpha_D = \frac{\\mu}{|D| + \\mu}$, where $\\mu$ is set empirically. The final formula is:\n$$\frac{f_{q_i, D} + \\mu \frac{c_{q_i}}{|C|}}{|D| + \\mu}$$\nwhere $f_{q_i, D}$ is the term frequency in document $D$, and $c_{q_i}$ is the term frequency in entire collection $C$. We could set $\\mu = 1000$. ", "id": 4, "summery": "Details of the micro search engine, including the steps for query processing, indexing techniques, and retrieval models.", "tags": ["Software Engineering", "Full Stack", "Search Engine"], "title": "Low level Design -- Search Engine, Personal Website", "type": "documentation"}, "text": ["itle", "personal", "website", "low", "level", "design", "search", "engine", "author", "author", "yunfei", "luo", "maketitle", "extbf", "1", "overview", "includegraphics", "scale", "0", "28", "back", "end", "overview", "jpg", "centerline", "extbf", "figure", "1", "micro", "search", "engine", "architecture", "extbf", "2", "pre", "processing", "extbf", "21", "processing", "documents", "independent", "interaction", "frontend", "backend", "process", "done", "periodically", "new", "articles", "added", "database", "process", "follows", "steps", "tokenize", "letter", "lower", "case", "remove", "dot", "abbreviation", "words", "ii", "stemming", "snowball", "stemmer", "called", "porter", "2", "iii", "stopword", "removal", "remove", "non", "significant", "words", "concise", "list", "python", "package", "nltk", "extbf", "22", "processing", "queries", "query", "request", "coming", "frontend", "query", "terms", "pre", "processed", "querying", "functions", "executed", "processing", "steps", "steps", "processing", "documents", "21", "extbf", "3", "indexing", "inverted", "index", "", "indexing", "mainly", "retrieval", "model", "rank", "documents", "given", "query", "terms", "inverted", "index", "inverted", "list", "contains", "necessary", "information", "stored", "terms", "specifically", "inverted", "index", "defined", "map", "term", "mapsto", "map", "document", "id", "mapsto", "list", "positions", "example", "term", "learning", "occur", "document", "1", "3", "fifth", "word", "document", "1", "second", "word", "document", "2", "index", "term", "looks", "learning", "mapsto", "document", "1", "mapsto", "1", "5", "document", "3", "mapsto", "2", "4", "term", "frequency", "document", "length", "term", "doc", "id", "total", "length", "list", "positions", "document", "specified", "id", "collection", "frequency", "length", "list", "term", "extbf", "4", "retrieval", "models", "key", "element", "ranking", "documents", "given", "query", "terms", "following", "options", "algorithms", "extbf", "41", "bm25", "formula", "information", "reference", "search", "engines", "information", "retrieval", "practice", "wb", "croft", "d", "metzler", "t", "strohman", "2015", "bm25", "bm", "stands", "best", "match", "known", "probabilistic", "retrieval", "model", "take", "document", "term", "frequency", "account", "consider", "query", "term", "frequency", "micro", "search", "engine", "common", "form", "bm25", "reference", "information", "specifically", "score", "document", "given", "query", "terms", "calculated", "sum", "q", "log", "rac", "n", "n", "0", "5", "n", "0", "5", "cdot", "rac", "k", "1", "1", "f", "k", "f", "cdot", "rac", "k", "2", "1", "qf", "k", "2", "qf", "q", "set", "terms", "query", "terms", "n", "total", "number", "documents", "n", "document", "frequency", "number", "documents", "contain", "term", "", "f", "term", "frequency", "document", "qf", "term", "frequency", "query", "terms", "weighting", "parameters", "k", "1", "k", "2", "k", "set", "empirically", "science", "", "k", "1", "k", "2", "determine", "importance", "document", "term", "frequency", "query", "term", "frequency", "respectively", "k", "normalized", "term", "determined", "k", "k", "1", "1", "b", "b", "cdot", "rac", "dl", "avdl", "b", "empirical", "parameter", "dl", "document", "length", "avdl", "average", "length", "documents", "set", "magic", "parameters", "k", "1", "1", "1", "k", "2", "10", "b", "0", "6", "", "extbf", "42", "query", "likelihood", "formula", "information", "reference", "search", "engines", "information", "retrieval", "practice", "wb", "croft", "d", "metzler", "t", "strohman", "2015", "query", "likelihood", "known", "probabilistic", "retrieval", "model", "depends", "language", "model", "smoothing", "techniques", "dirichlet", "smoothing", "specifically", "calculate", "score", "document", "alpha", "d", "p", "q", "d", "alpha", "d", "p", "q", "c", "p", "q", "d", "probability", "query", "term", "occur", "document", "d", "p", "q", "c", "probability", "query", "term", "occur", "entire", "collection", "c", "", "alpha", "d", "dirichlet", "smoothing", "coefficient", "determined", "alpha", "d", "rac", "mu", "d", "mu", "mu", "set", "empirically", "final", "formula", "rac", "f", "q", "d", "mu", "rac", "c", "q", "c", "d", "mu", "f", "q", "d", "term", "frequency", "document", "d", "c", "q", "term", "frequency", "entire", "collection", "c", "", "set", "mu", "1000", ""]}, "4": {"obj": {"docs": [], "path": "articles/blogs/paper_review_artistic_style.pdf", "text": "Paper Review\nAuthor: Yunfei Luo\nMay 12, 2020\n||||||||||||||||||||||||||||||||||||||||\nA Neural Algorithm of Artistic Style, by Gatys, Ecker, and Bethge\nReference Paper URL: https://arxiv.org/abs/1508.06576\nIntroduction/Main Goal\nThe paper was published in 2015. The main goal of the paper is to introduce an artificial system\nthat could create artistic images like what human could do with painting. The core of the system\nis a neural algorithm based on Deep Neural Networks. A sub-goal of the paper is to describe how\nhuman create and perceive artistic images, with algorithmic approach.\nWhat's New/Improvement\nThe authors are not trying improve, but rather, explore a new field of application of Deep Neural\nNetworks. They notice that, during the image processing by the neural networks, the actual features\n(the mapping of different filtered versions of image) and the correlation between different filters can\nbe individually visualized at each layer. They called them \"content representation\" and \"style rep-\nresentation\" respectively. So they are thinking about combining the representations of content and\nstyle to make something out.\nObservations\nAs a paper on the neural networks, the input and output in this case are both images, with the\nnormal image structures, i.e. the 2-D matrix of pixels. More specifically, the inputs are two images,\none for capturing the content representation, one for extracting style representation. The output is\nan image that combine the content and style representation through image reconstruction. More-\nover, there do exists a hidden state. Since during the match of content and style, if emphasizing\nmore on the content, it will be obvious to detect what was the original photograph with less variant\nin the style. Same as if emphasizing more on the style, then content of the image might be hard to\nsee, i.e. the image would be too abstractionism. So the hidden state would be some reconstructed\nimage with \"just-right\" weights for content and style.\nResult\nIn order to dealing with this tasks, the authors done it through a optimization problem on minimiz-\ning the linear combination of the loss functions of content and style. The weights, or the coe\u000ecients\nof the loss functions could be understand as the \"regularizers\" that serves for the extent of how much\nthe image emphasize on content and style. For the result that the authors got (page 5 in the paper):\n\nIt seems like the Deep Neural Networks perform pretty well on applying different artistic styles, from\nlearning of other artworks, on the photo shown in A. To intuitively interpret these results, the neu-\nral algorithm do effectively facsimile the photograph with artistic styles of some well-known artists,\nsuch as J.M.W. Turner and Vincent Van Gogh.\n\nExtension/Follow up\nWhat would happen if combining content with content, and style with style? An intuitive instance\nwould be, suppose that there is a photo of a cat, and another photo of a dog, what if we use the\ncontent representations of these two images from the Deep Neural Network for image reconstruc-\ntion? How to construct the optimization problem in this case, in order to made an image that have\nthe key content in both original images with relatively \"just right\" weights and positions? These\nfollow-up questions others the possible extension for the work presented in the paper.\n", "id": 6, "summery": "The main goal of the paper is to introduce an artificial system that could create artistic images like what human could do with painting.", "tags": ["Machine Learning", "Artificial Intelligence", "Neural Networks", "Numerical Optimization", "Image Processing"], "type": "blog", "title": "Image Reconstruction with Artistic Style, Paper Review"}, "text": ["paper", "review", "author", "yunfei", "luo", "12", "2020", "neural", "algorithm", "artistic", "style", "gatys", "ecker", "bethge", "reference", "paper", "url", "https", "arxiv", "org", "abs", "1508", "06576", "introduction", "main", "goal", "paper", "published", "2015", "main", "goal", "paper", "introduce", "artificial", "system", "create", "artistic", "images", "human", "painting", "core", "system", "neural", "algorithm", "based", "deep", "neural", "networks", "sub", "goal", "paper", "describe", "human", "create", "perceive", "artistic", "images", "algorithmic", "approach", "s", "new", "improvement", "authors", "trying", "improve", "explore", "new", "field", "application", "deep", "neural", "networks", "notice", "image", "processing", "neural", "networks", "actual", "features", "mapping", "different", "filtered", "versions", "image", "correlation", "different", "filters", "individually", "visualized", "layer", "called", "content", "representation", "style", "rep", "resentation", "respectively", "thinking", "combining", "representations", "content", "style", "make", "observations", "paper", "neural", "networks", "input", "output", "case", "images", "normal", "image", "structures", "2", "d", "matrix", "pixels", "specifically", "inputs", "two", "images", "capturing", "content", "representation", "extracting", "style", "representation", "output", "image", "combine", "content", "style", "representation", "image", "reconstruction", "exists", "hidden", "state", "match", "content", "style", "emphasizing", "content", "obvious", "detect", "original", "photograph", "variant", "style", "emphasizing", "style", "content", "image", "hard", "image", "abstractionism", "hidden", "state", "reconstructed", "image", "right", "weights", "content", "style", "result", "order", "dealing", "tasks", "authors", "done", "optimization", "problem", "minimiz", "ing", "linear", "combination", "loss", "functions", "content", "style", "weights", "coe", "cients", "loss", "functions", "understand", "regularizers", "serves", "extent", "image", "emphasize", "content", "style", "result", "authors", "got", "page", "5", "paper", "deep", "neural", "networks", "perform", "pretty", "applying", "different", "artistic", "styles", "learning", "artworks", "photo", "intuitively", "interpret", "results", "neu", "ral", "algorithm", "effectively", "facsimile", "photograph", "artistic", "styles", "known", "artists", "jmw", "turner", "vincent", "van", "gogh", "extension", "follow", "happen", "combining", "content", "content", "style", "style", "intuitive", "instance", "suppose", "photo", "cat", "photo", "dog", "content", "representations", "two", "images", "deep", "neural", "network", "image", "reconstruc", "tion", "construct", "optimization", "problem", "case", "order", "made", "image", "key", "content", "original", "images", "relatively", "right", "weights", "positions", "follow", "questions", "possible", "extension", "work", "presented", "paper"]}, "5": {"obj": {"docs": [], "path": "articles/blogs/paper_review_char_level_text_classification.pdf", "text": "Paper Review\nAuthor: Yunfei Luo\nMay 12, 2020\n||||||||||||||||||||||||||||||||||||||||\nCharacter-level Convolutional Networks for Text Classi\fcation, by Zhang, Zhao, and LeCun\nReference Paper URL: https://arxiv.org/abs/1509.01626\nIntroduction/Main Goal\nThe paper was published in 2016. The main goal of the paper is to exemplify the performance of\nConvNets (Convolutional Networks) on text classification, based on Character-level. That is, to\nshow the ability of ConvNets understand the text (for the task of classification) without knowing\nthe knowledge from words and semantic structure of the language.\nWhat's New/Improvement\nThe authors are trying to improve upon the traditional text classification. As pointed by the au-\nthors, most of the machine learning classifiers for text classification nowadays are based on words.\nHowever, the authors offers a new approach to the task, i.e. treating the text as raw signal at char-\nacter level, rather than word level. More specifically, instead of present word at each entry of the\nvector representation for the text, the signal present single character at each entry. Such approach\nis supposed to be more effective and perform better with large scale dataset.\nObservations\nThis is also a paper on Neural Networks. The input is a text, and the output is a class that the\ntext belongs to. More specifically, the input text will be numerically transformed into a matrix with\ndimension m * l, such that m defines the domain of unit character depends on the input language,\nand l denotes the total length of the sequence of characters that we care about in the text. In this\npaper, the authors believe that l = 1014 is an appropriate length, since it is enough for catching\nthe key information in a text. The output class is simply in string format, for example, \"sport\",\n\"finance\", \"entertainment\", etc. Although in the paper, the authors use supervised learning to train\nthe Networks, all the class of the given texts are known, in practice, there do exist some unknown\nstate. The hidden node would be the actual class that the texts belong to. The topology of the\nhidden nodes could be several independent trees, each with a broad class as root. For example, the\nclass \"sport\", there would be some sub-class under this class, such as \"basketball\", \"swimming\",\n\"mixed martial arts\", etc.\nResult\nThe result that the authors obtained is shown as followed (page 6 in the paper):\n\nThe table of error shows that overall, the character-level ConvNets performed well. A more de-\ntailed comparison of the errors with other text classification model is offered at page 7:\n\nThe figure above shows that although the character-level ConvNets does not perform that well\nwith the dataset \"AG News\" compare with other models (except Bag-pf-means, because this model\nhas more errors in all the dataset cases), the overall values of errors made by the character-level\nConvNets is considerable. The most important point is that the character-level based ConvNets\ndoes not need dictionary for training, so that the entire training process is much more effective than\nthe other models.\nExtension/Follow up\nSome deficiency would be obvious that the character-level ConvNets might not perform well with\nnon-symbol-based language, such as Chinese. In this paper, the authors deal with this case (the\ndataset of Sogou News) by transform the Chinese characters into Pinyin. However, Pinyin and\nChinese characters are not an one-to-one mapping, but rather an onto mapping, from characters to\nPinyin. Placing different characters at the same place could mean extremely different things. So\nwould it be better if we split each character into strokes (such as point and across, which is also a\nfinite set), then use this sequence of strokes as raw input signals? Such follow-up questions could\nform the extension for the work presented in the paper.\n", "id": 7, "summery": "The main goal of the paper is to exemplify the performance of ConvNets (Convolutional Networks) on text classification, based on Character-level.", "tags": ["Machine Learning", "Artificial Intelligence", "Neural Networks", "Numerical Optimization", "Classification"], "type": "blog", "title": "Character Level Text Classification, Paper Review"}, "text": ["paper", "review", "author", "yunfei", "luo", "12", "2020", "character", "level", "convolutional", "networks", "text", "classi", "cation", "zhang", "zhao", "lecun", "reference", "paper", "url", "https", "arxiv", "org", "abs", "1509", "01626", "introduction", "main", "goal", "paper", "published", "2016", "main", "goal", "paper", "exemplify", "performance", "convnets", "convolutional", "networks", "text", "classification", "based", "character", "level", "show", "ability", "convnets", "understand", "text", "task", "classification", "knowing", "knowledge", "words", "semantic", "structure", "language", "s", "new", "improvement", "authors", "trying", "improve", "traditional", "text", "classification", "pointed", "au", "thors", "machine", "learning", "classifiers", "text", "classification", "based", "words", "authors", "offers", "new", "approach", "task", "treating", "text", "raw", "signal", "char", "acter", "level", "word", "level", "specifically", "present", "word", "entry", "vector", "representation", "text", "signal", "present", "single", "character", "entry", "approach", "supposed", "effective", "perform", "better", "large", "scale", "dataset", "observations", "paper", "neural", "networks", "input", "text", "output", "class", "text", "belongs", "specifically", "input", "text", "numerically", "transformed", "matrix", "dimension", "m", "l", "m", "defines", "domain", "unit", "character", "depends", "input", "language", "l", "denotes", "total", "length", "sequence", "characters", "care", "text", "paper", "authors", "believe", "l", "1014", "appropriate", "length", "catching", "key", "information", "text", "output", "class", "simply", "string", "format", "example", "sport", "finance", "entertainment", "paper", "authors", "supervised", "learning", "train", "networks", "class", "given", "texts", "known", "practice", "exist", "unknown", "state", "hidden", "node", "actual", "class", "texts", "belong", "topology", "hidden", "nodes", "independent", "trees", "broad", "class", "root", "example", "class", "sport", "sub", "class", "class", "basketball", "swimming", "mixed", "martial", "arts", "result", "result", "authors", "obtained", "followed", "page", "6", "paper", "table", "error", "shows", "overall", "character", "level", "convnets", "performed", "de", "tailed", "comparison", "errors", "text", "classification", "model", "offered", "page", "7", "figure", "shows", "character", "level", "convnets", "perform", "dataset", "ag", "news", "compare", "models", "bag", "pf", "means", "model", "errors", "dataset", "cases", "overall", "values", "errors", "made", "character", "level", "convnets", "considerable", "important", "point", "character", "level", "based", "convnets", "dictionary", "training", "entire", "training", "process", "effective", "models", "extension", "follow", "deficiency", "obvious", "character", "level", "convnets", "perform", "non", "symbol", "based", "language", "chinese", "paper", "authors", "deal", "case", "dataset", "sogou", "news", "transform", "chinese", "characters", "pinyin", "pinyin", "chinese", "characters", "mapping", "mapping", "characters", "pinyin", "placing", "different", "characters", "place", "mean", "extremely", "different", "things", "better", "split", "character", "strokes", "point", "finite", "set", "sequence", "strokes", "raw", "input", "signals", "follow", "questions", "form", "extension", "work", "presented", "paper"]}, "6": {"obj": {"docs": [], "path": "articles/reports/studentlife_spring2020_report.pdf", "text": "Independent Study Report\nUniversity of Massachusetts Amherst\nInstructors: Madalina Fiterau, Iman Deznabi\nStudent: Yunfei Luo\nSpring 2020\nMay 12, 2020\n||||||||||||||||||||||||||||||||||||||||\nPersonalized Student Stress Prediction with Deep Multitask Network\nAbstract\nIn this semester, I'm working on predicting student stress with putting students in groups, in order\nto explore the possibility to make the original personalized model more applicable. Though it is\nhard for the \"grouplized\" model to have better performance than the personalized model, my ex-\nperiments shows that grouping students by the average stress level could have F1 score that is really\nclose to the score achieved by the personalized model.\n1. Introduction and Previous work\nThe previous state-of-the-art model is called Cross-Personal Activity LSTM Multitask Auto-Encoder\nNetwork (CALM-Net), see Personalized Student Stress Prediction with Deep Multitask Network by\nAbhinav Shaw, Natcha Simsiri, Iman Deznabi, Madalina Fiterau, Tauhidur Rahman.\nThe model is constituted by a Long Term Short Memory (LSTM) autoencoder connected by fully\nconnected layers, then connected by sub multi-layer-perceptrons (MLP) for each students. I'm\nmainly working on the sub MLP part.\nThe main problem is that when we have a new student, without collecting some data from the\nstudent, it is hard for the personalized model to make prediction due to the lack in training data.\nSo for the sub MLP, instead of building them for each student, we build them for each group of\nstudents. So when a new student come, instead of collecting data from the student, we just need\nto collect some features of the students, then we could put the student into the group that contains\nstudents who share similar characteristics with the new student, then make prediction.\n\nFigure 1.Personalized Model\nFigure 2.Grouplized Model\n2. Background Information\nThe StudentLife dataset was conducted in Dartmouth college where passive sensing and survey data\nwas collected over 10 weeks among 48 students.\n3. Methods\n3.1. Density Based Clustering based on Dynamic Time Warping (DTW) on series of stress labels\nThe stress labels we have for each student form a time series data. Since the stress labels for\n\nthe students falls in different set of days during the 2 months range, using distance criteria like Eu-\nclidean and Manhattan distance is not reasonable. In order to find the similarity among students,\nstudents can be clustered based on the DTW distance, that considering the distortion of the data.\nSince each student have different number of stress label recorded, the lengths of these time se-\nries data are different. So the methods based on finding centroids such K-Means and Mean-shift are\nnot applicable. Instead, hierarchical clustering methods can be used in this case. Density-Based-\nSpatial-Clustering-of-Applications-with-Noise (DBSCAN) is the one I used for clustering these series\ndata. The noise data points were greedily assigned to the existed groups that are the closest to them.\nFigure 3. samples of clusters.\nThe x-axis is the time (days in a year + (hours in the day / 24)), the y-axis is the stress label\n\n3.2. K-Means Clustering on aggregated stress labels, i.e. average stress labels\nConsidering that the density based clustering methods based on DTW is a bit complex, I sim-\nply aggregated the series data with their means to be the data point. Then the clustering becomes\nmuch easier. Though I use K-Means for clustering, it is nothing but put thresholds to split the data\npoints.\nFigure 4. clusters visualize, where x-axis is the average stress labels\n3.3. Density Based Clustering on chosen features from aggregated surveys score\nThe ideal way is to clustering students based on surveys score. So for a new student, we could\nfirst collect the survey results, then put the student in to proper cluster. For now, I had use the\nfeatures: average hours slept, average deadline per week, and mode sleep rating. In order to guar-\nantee that in the training dataset, no group contains only one student, I use the same methods in\n3.1: use DBSCAN first, then put the noise data in the closest clusters.\n\nFigure 5. Clusters visualize with three chosen features from surveys\n4. Experiment results:\nThe model evaluation method I used is 5-fold cross validation. The metrics include F1 score and\nAUC were averaged across the 5 splits. I've also include the results of original data in the table, i.e.\neach group contain exactly one student.\nTable 1. The best results that each different clustering method obtained\n5. Conclusion and Future work\nThe results from experiments shows that using clusters based on average stress labels has better\n\nperformance. However, in order to know how well a model performed, we need to run leave one out\nvalidations, which haven't being completed. After that, we could know how the model generalized\namong each individual.\nIn addition, there are still many other surveys scores that haven't been used in clustering. In\norder to use these features, I need to do more work on knowing how the scores of different types of\nsurveys are aggregated.\nA. Appendix\nA.1. Model Configuration\nWeights for Losses: alpha = 0:0001 for autoencoder reconstruction error, beta = 1 for classi\fcation error\nAuto-Encoder bottleneck size: 128\nShared Layer size: 256\nUser(Group) Layer size: 64\nEpochs: 500\nGradient Descent step size: 0.000001\nL2 norm regularization coeff: 0.0001\nDropout probabilities: None\nValidation method: 5-fold validation, strati\fed splitting by the group-id/stress-label pairs\n", "id": 5, "summery": "Open source project on predicting student's stress with Multitask Learning and Time series data. The Dataset, StudentLife, was collected by a program in Dartmouth College.", "tags": ["Machine Learning", "Artificial Intelligence", "Open Source", "Neural Networks"], "type": "report", "title": "Student Stress Prediction, Machine Learning Research Project"}, "text": ["independent", "study", "report", "university", "massachusetts", "amherst", "instructors", "madalina", "fiterau", "iman", "deznabi", "student", "yunfei", "luo", "spring", "2020", "12", "2020", "personalized", "student", "stress", "prediction", "deep", "multitask", "network", "abstract", "semester", "m", "working", "predicting", "student", "stress", "putting", "students", "groups", "order", "explore", "possibility", "make", "original", "personalized", "model", "applicable", "hard", "grouplized", "model", "better", "performance", "personalized", "model", "ex", "periments", "shows", "grouping", "students", "average", "stress", "level", "f1", "score", "close", "score", "achieved", "personalized", "model", "1", "introduction", "previous", "work", "previous", "state", "art", "model", "called", "cross", "personal", "activity", "lstm", "multitask", "auto", "encoder", "network", "calm", "net", "personalized", "student", "stress", "prediction", "deep", "multitask", "network", "abhinav", "shaw", "natcha", "simsiri", "iman", "deznabi", "madalina", "fiterau", "tauhidur", "rahman", "model", "constituted", "long", "term", "short", "memory", "lstm", "autoencoder", "connected", "fully", "connected", "layers", "connected", "sub", "multi", "layer", "perceptrons", "mlp", "students", "m", "mainly", "working", "sub", "mlp", "part", "main", "problem", "new", "student", "collecting", "data", "student", "hard", "personalized", "model", "make", "prediction", "due", "lack", "training", "data", "sub", "mlp", "building", "student", "build", "group", "students", "new", "student", "come", "collecting", "data", "student", "collect", "features", "students", "put", "student", "group", "contains", "students", "share", "similar", "characteristics", "new", "student", "make", "prediction", "figure", "1", "personalized", "model", "figure", "2", "grouplized", "model", "2", "background", "information", "studentlife", "dataset", "conducted", "dartmouth", "college", "passive", "sensing", "survey", "data", "collected", "10", "weeks", "48", "students", "3", "methods", "31", "density", "based", "clustering", "based", "dynamic", "time", "warping", "dtw", "series", "stress", "labels", "stress", "labels", "student", "form", "time", "series", "data", "stress", "labels", "students", "falls", "different", "set", "days", "2", "months", "range", "distance", "criteria", "eu", "clidean", "manhattan", "distance", "reasonable", "order", "find", "similarity", "students", "students", "clustered", "based", "dtw", "distance", "considering", "distortion", "data", "student", "different", "number", "stress", "label", "recorded", "lengths", "time", "se", "ries", "data", "different", "methods", "based", "finding", "centroids", "k", "means", "mean", "shift", "applicable", "hierarchical", "clustering", "methods", "case", "density", "based", "spatial", "clustering", "applications", "noise", "dbscan", "clustering", "series", "data", "noise", "data", "points", "greedily", "assigned", "existed", "groups", "closest", "figure", "3", "samples", "clusters", "x", "axis", "time", "days", "hours", "24", "y", "axis", "stress", "label", "32", "k", "means", "clustering", "aggregated", "stress", "labels", "average", "stress", "labels", "considering", "density", "based", "clustering", "methods", "based", "dtw", "bit", "complex", "sim", "ply", "aggregated", "series", "data", "means", "data", "point", "clustering", "easier", "k", "means", "clustering", "put", "thresholds", "split", "data", "points", "figure", "4", "clusters", "visualize", "x", "axis", "average", "stress", "labels", "33", "density", "based", "clustering", "chosen", "features", "aggregated", "surveys", "score", "ideal", "way", "clustering", "students", "based", "surveys", "score", "new", "student", "collect", "survey", "results", "put", "student", "proper", "cluster", "features", "average", "hours", "average", "deadline", "mode", "sleep", "rating", "order", "guar", "antee", "training", "dataset", "group", "contains", "student", "methods", "3", "1", "dbscan", "put", "noise", "data", "closest", "clusters", "figure", "5", "clusters", "visualize", "three", "chosen", "features", "surveys", "4", "experiment", "results", "model", "evaluation", "method", "5", "fold", "cross", "validation", "metrics", "f1", "score", "auc", "averaged", "5", "splits", "ve", "results", "original", "data", "table", "group", "contain", "exactly", "student", "table", "1", "best", "results", "different", "clustering", "method", "obtained", "5", "conclusion", "future", "work", "results", "experiments", "shows", "clusters", "based", "average", "stress", "labels", "better", "performance", "order", "know", "model", "performed", "run", "leave", "validations", "haven", "t", "completed", "know", "model", "generalized", "individual", "addition", "surveys", "scores", "haven", "t", "clustering", "order", "features", "work", "knowing", "scores", "different", "types", "surveys", "aggregated", "appendix", "a1", "model", "configuration", "weights", "losses", "alpha", "0", "0001", "autoencoder", "reconstruction", "error", "beta", "1", "classi", "cation", "error", "auto", "encoder", "bottleneck", "size", "128", "shared", "layer", "size", "256", "user", "group", "layer", "size", "64", "epochs", "500", "gradient", "descent", "step", "size", "0", "000001", "l2", "norm", "regularization", "coeff", "0", "0001", "dropout", "probabilities", "validation", "method", "5", "fold", "validation", "strati", "ed", "splitting", "group", "id", "stress", "label", "pairs"]}}